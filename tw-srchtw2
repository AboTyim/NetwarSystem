#!/usr/bin/python
import csv, json, os, random, re, sys, time, redis, tweepy, getpass, datetime
import configparser
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
from elasticsearch_dsl import Q
import ssl
from elasticsearch.connection import create_ssl_context
import squish2, requests

#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()
sysconf = configparser.ConfigParser()
sysconf.read('/etc/netwar/netwar.conf')

config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')
auth = tweepy.OAuthHandler(config['API']['consumer_key'], config['API']['consumer_secret'])
auth.set_access_token(config['API']['access_token_key'], config['API']['access_token_secret'])
api = tweepy.API(auth)

if(sysconf['SYSTEM']['elksg'][:5] == "https"):
	try:
		ssl_context = create_ssl_context(cafile='/etc/netwar/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		client = Elasticsearch(sysconf['SYSTEM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(sysconf['SYSTEM']['elksguser'], sysconf['SYSTEM']['elksgpass']))
	except:
		sys.exit()
else:
	client = Elasticsearch(sysconf['SYSTEM']['elksg'])

q = Q(squish2.mkfilter("user.screen_name", sys.argv[2]))

s = Search(using=client, index=sys.argv[1]).filter('range', created_at={"gte": "now-1d", "lt": "now"}).query(q)

ids = []
cnt = 0
for response in s.scan():
	ids.append(response['id'])

		
res = api.statuses_lookup(ids)
for thing in res:
		print(thing.user.screen_name + ",http://twitter.com/" + thing.user.screen_name + "/status/" + thing.id_str + "," + str(thing.retweet_count + thing.favorite_count))
		#print(thing['retweet_count'])
		#print(thing['favorite_count'])
	
