#!/usr/bin/python
import csv, json, os, random, re, sys, time, redis, tweepy, getpass
import configparser
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
from walrus import *
import squish2
#import psutil, getpass, setproctitle, platform

def load_lists(myname):
	lists = api.lists_all(myname)
	if(len(work) == 0 ):
		seen.clear()
	for list in lists:
		if re.match("pro-", list.slug):
			for member in tweepy.Cursor(api.list_members,myname,list.slug).items():
				if(member.screen_name not in seen):
					print("adding " + list.slug + " " +  member.screen_name)
					seen.add(member.screen_name)
					adds.add(member.screen_name)

def get_all_tweets(acct_name):
	maxtweet = "9999999999999999999"
	if client.indices.exists(index="tu" + getpass.getuser()):
		s = Search(using=client, index="tu"+ getpass.getuser()).query("match", screen_name=acct_name)
		resp = s.execute()
		if(resp):
			maxtweet = resp[0].status.id_str
	bod = ""
	cnt1 = 0
	cnt2 = 0
	for tweet in tweepy.Cursor(api.user_timeline, id=acct_name,tweet_mode='extended').items():
		cnt1 = cnt1 + 1
		cnt2 = cnt2 + 1
		if(tweet.id_str == maxtweet):
			print(maxtweet + " has been seen!!!")
			break
		print("adding " + str(acct_name) + " " + str(tweet.id) + " " + " " + str(cnt2))
		bod = bod + "{ \"index\" : { \"_index\" : \"tw" + getpass.getuser() + "\", \"_type\" : \"tweets\", \"_id\" : \"" + str(tweet.id) + "\"} }\n"
		bod = bod + json.dumps(tweet._json) + "\n"
		if(cnt1 == 800):
			try:
				client.bulk(index="tw" + getpass.getuser(),doc_type="tweets",body=bod)
				bod = ""
				cnt1 = 0
			except (RuntimeError, TypeError, NameError):
				pass
	# leftovers
	if(len(bod) > 0):
		try:
			client.bulk(index="tw" + getpass.getuser(),doc_type="tweets",body=bod)
		except (RuntimeError, TypeError, NameError):
			pass

# main begin
config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')

auth = tweepy.OAuthHandler(config['API']['consumer_key'], config['API']['consumer_secret'])
auth.set_access_token(config['API']['access_token_key'], config['API']['access_token_secret'])
api = tweepy.API(auth)
my = api.verify_credentials()

if(config['STREAM']['elksg'][:5] == "https"):
	print(config['STREAM']['elksg'][:5])
	try:
		ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		client = Elasticsearch(config['STREAM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(config['STREAM']['elksguser'], config['STREAM']['elksgpass']))
	except:
		sys.exit()
else:
	client = Elasticsearch(config['STREAM']['elksg'])

wal = Walrus(host='localhost', port=6379, db=0)
adds = wal.Set(getpass.getuser() + "adds")
work = wal.Set(getpass.getuser() + "work")
seen = wal.Set(getpass.getuser() + "seen")


load_lists(my.screen_name)

if(len(adds) > 0):
	nextid = adds.pop()
	work.add(nextid)
	print("adds: " + nextid)
else:
	nextid = work.pop()
	print("work: " + str(nextid))

get_all_tweets(nextid)

try:
	y = api.get_user(nextid)
	if y:
		y = squish2.squishuser(y)
		twbod = "{ \"index\" : { \"_index\" : \"tu" + getpass.getuser() + "\", \"_type\" : \"userid\", \"_id\" : \"" + y.id_str + "\" }\n"
		twbod = twbod + json.dumps(y._json)
		client.bulk(index="tu" + getpass.getuser(),doc_type="userid",body=twbod)
except (RuntimeError, TypeError, NameError):
	print("tu failed")
	pass


