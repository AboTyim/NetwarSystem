#!/usr/bin/python
import datetime, platform, getpass
import csv, json, pprint, os, random, re, sys, time, datetime
import redis, walrus, tweepy, configparser, ssl
import psutil, getpass, setproctitle, platform
from time import gmtime
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
from elasticsearch.connection import create_ssl_context
from urllib3.exceptions import ProtocolError
import squish2, requests

requests.packages.urllib3.disable_warnings()

config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')
sysconf = configparser.ConfigParser()
sysconf.read('/etc/netwar/netwar.conf')


# set buffer size
max = 50
if(len(sys.argv) > 2):
	max = int(sys.argv[2])

try:
	auth = tweepy.OAuthHandler(config['API']['consumer_key'], config['API']['consumer_secret'])
	auth.set_access_token(config['API']['access_token_key'], config['API']['access_token_secret'])
	api = tweepy.API(auth)
	y = api.verify_credentials()
	print(getpass.getuser() + " " +  y.screen_name)
except tweepy.error.TweepError:
	print(sys.argv[1] + " " + config[API].account)
	exit(1)

if(sysconf['SYSTEM']['elksg'][:5] == "https"):
	try:
		ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		# timeout bumped from 60 to 120 - userid based streams are fine,
		# high volume hashtag based streams timeout. 
		# 2019-08-03 timeouts were probably Neo4j performance issues, now corrected.
		client = Elasticsearch(sysconf['SYSTEM']['elksg'], ssl_context=ssl_context, timeout=120, http_auth=(sysconf['SYSTEM']['elksguser'], sysconf['SYSTEM']['elksgpass']))
	except() as prob:
		print(prob)
		sys.exit()
else:
	client = Elasticsearch(sysconf['SYSTEM']['elksg'])

# set index name

myfile = sys.argv[1]
myidx = sys.argv[1].lower()
myidx = re.sub(".txt", "",myidx)
myidx = re.sub(".csv", "",myidx)

<<<<<<< HEAD
client.indices.create(index='tw' + myidx, body = squish2.formattweets(), ignore=400)
client.indices.create(index='tu' + myidx, body = squish2.formatusers(), ignore=400)
=======
request_body = {
 "settings" : { "number_of_shards" : 3, "number_of_replicas" : 1},
       'mappings' : {'tweets' : { 'properties' : {
          'coordinates' : {'properties' : {'coordinates' : {'type' : 'geo_point'},'type' : {'type' : 'text'}}},
          'created_at' : {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
          'id_str' : {'type' : 'keyword'},
          'lang' :   {'type' : 'keyword'},
          'source' : {'type' : 'keyword'},
          'text' :   {'type' : 'text'},
          'user' : {'properties' : {'created_at' : {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
                                    'description' : {'type' : 'text'},
                                    'name' : {'type' : 'text'},
                                    'screen_name' : {'type' : 'text'}}}}}}}

client.indices.create(index='tw' + myidx, body = request_body, ignore=400)

request_body = {
        "settings" : { "number_of_shards" : 3, "number_of_replicas": 1},
       'mappings' : {'userid' : { 'properties' : {
          'created_at' : {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
          'status_at' :  {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
          'collected_at' :  {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
          'coordinates' : {'properties' : {'coordinates' : {'type' : 'geo_point'},'type' : {'type' : 'text'}}},
          'id_str' : {'type' : 'keyword'},
          'lang' :   {'type' : 'keyword'},
          'source' : {'type' : 'keyword'},
          'text' :   {'type' : 'text'},
          'user' :   {'properties' : {'created_at' : {'type' : 'date',  'format' : 'EEE MMM dd HH:mm:ss Z YYYY'},
                                      'description' : {'type' : 'text'},
                                      'name' :        {'type' : 'text'},
                                      'screen_name' : {'type' : 'text'}}}}}}}

client.indices.create(index='tu' + myidx, body = request_body, ignore=400)
>>>>>>> bb9b5312ca15c5e7a631251145b43a2eaea98def

squish2.perflog(client, "begin streaming " + myidx, "")

class StreamApi(tweepy.StreamListener):
	def on_status(self, status):
		global twbod
		global tubod
		global myidx
		global cnt
		global config
		status._json.pop('coordinates', None)
		status._json.pop('contributors', None)
		status._json.pop('is_quote_status', None)
		status._json.pop('in_reply_to_status_id', None)
		status._json.pop('favorite_count', None)
		status._json.pop('in_reply_to_screen_name', None)
		status._json.pop('in_reply_to_user_id', None)
		status._json.pop('retweet_count', None)
		status._json.pop('favorite', None)
		status._json.pop('favorited', None)
		status._json.pop('favorite_count', None)
		status._json.pop('in_reply_to_user_id_str', None)
		status._json.pop('possibly_sensitive', None)
		status._json.pop('in_reply_to_status_id_str', None)
		status._json.pop('quoted_status', None)
		status._json.pop('quoted_status_id', None)
		status._json.pop('quoted_status_id_str', None)
		status._json.pop('retweeted', None)
		#status._json.pop('retweeted_status', None)
		status._json.pop('retweets', None)
		status._json.pop('retweet', None)
		status._json.pop('user.profile_background_color', None)
		status._json.pop('user.profile_background_image_url', None)
		status._json.pop('user.profile_background_image_url_https', None)
		status._json.pop('user.profile_background_tile', None)
		status._json.pop('user.profile_banner_url', None)
		status._json.pop('user.profile_image_url', None)
		status._json.pop('user.profile_image_url_https', None)
		status._json.pop('user.profile_link_color', None)
		status._json.pop('user.profile_location', None)
		status._json.pop('user.profile_sidebar_border_color', None)
		status._json.pop('user.profile_sidebar_fill_color', None)
		status._json.pop('user.profile_text_color', None)
		status._json.pop('user.profile_use_background_image', None)
		status._json['source'] = re.sub("<.*?>", "",status._json['source'])
		status._json['source'] = re.sub("\"", "",status._json['source'])

		twbod = twbod + "{ \"index\" : { \"_index\" : \"tw" + myidx + "\", \"_type\" : \"tweets\", \"_id\" : \"" + status.id_str + "\"} }\n"
		twbod = twbod + json.dumps(status._json) + "\n"
		tubod = tubod + "{ \"index\" : { \"_index\" : \"tu" + myidx + "\", \"_type\" : \"userid\", \"_id\" : \"" + status.user.id_str + "\" }\n"
		smuser = squish2.squishuser(status.user)
		tubod = tubod + json.dumps(smuser._json) + "\n"
		cnt = cnt + 1
# end tubod type userid
		try:
			status.retweeted_status
		except:
			cnt = cnt
		else:
			rtuser = squish2.squishuser(status.retweeted_status.user)
			tubod = tubod + "{ \"index\" : { \"_index\" : \"tu" + myidx + "\", \"_type\" : \"userid\", \"_id\" : \"" + status.retweeted_status.user.id_str + "\" }\n"
			tubod = tubod + json.dumps(rtuser._json) + "\n"
			cnt = cnt + 1
			if(cnt > max):
				# Yes, adding tweet count and users spotted count together
				# here is intentional. Production use revealed a 4:1 or 5:1
				# tweets to user data ratio, so this avoids annoying Elastic
				# without requiring tracking two different variable states.
				now = datetime.datetime.now()
				print(now.strftime("%a %b %d %X +0000 %Y") + " max " + str(max) + " count reached.")
				client.bulk(index="tw" + myidx,doc_type="tweets",body=twbod)
				k = client.bulk(index="tu" + myidx,doc_type="userid",body=tubod)
				squish2.perflog(client, "streaming " + myidx, str(len(twbod)) + " " + str(len(tubod)))
				twbod = ""
				tubod = ""
				cnt = 0


def on_error(self, status):
	if status == 420:
		sys.stderr.write('Enhance Your Calm; The App Is Being Rate Limited For Making Too Many Requests')
		return True
	else:
		sys.stderr.write('Error {}n'.format(status))
		return True

	
streamer = tweepy.Stream(auth=auth, listener=StreamApi(), timeout=30)

tfile = open(sys.argv[1], 'r')
terms = []
text = False
# one letter anywhere indicates text filter stream
# otherwise all numeric is userids
for thing in tfile:
	if(re.search("[a-zA-Z]",thing)):
		text = True	
	terms.append(thing.rstrip())

while True:
	twbod = ""
	tubod = ""
	cnt = 0
	try:
		if(text):
			print("Following " + str(len(terms)) + " terms")
			streamer.filter(None, terms)
		else:
			print("Following " + str(len(terms)) + " accounts")
			streamer.filter(follow=terms)
	except (ProtocolError, AttributeError, tweepy.error.TweepError) as prob:
		squish2.perflog(client, "stream error " + myidx, str(prob.args[0][0]['code']) + " " + str(prob.args[0][0]['message']))
		print("################### ERROR #####################")
		print(str(prob.args[0][0]['code']) + " " + str(prob.args[0][0]['message']))
		print("################### ERROR #####################")
