#!/usr/bin/python
import datetime, platform, getpass
import csv, json, pprint, os, random, re, sys, time, datetime
import redis, walrus, tweepy, configparser, ssl
import psutil, getpass, setproctitle, platform
from time import gmtime, strftime
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
from elasticsearch.connection import create_ssl_context
from urllib3.exceptions import ProtocolError
from py2neo import Graph, Node, Relationship, NodeMatcher, RelationshipMatcher
import squish2, requests

#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()

config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')

max = 100
if(len(sys.argv) > 2):
	max = int(sys.argv[2])

neog = Graph(config['STREAM']['neo4j'], user=config['STREAM']['neo4juser'], password=config['STREAM']['neo4jpass'])
neom = NodeMatcher(neog)


try:
	auth = tweepy.OAuthHandler(config['API']['consumer_key'], config['API']['consumer_secret'])
	auth.set_access_token(config['API']['access_token_key'], config['API']['access_token_secret'])
	api = tweepy.API(auth)
	y = api.verify_credentials()
	print(getpass.getuser() + " " +  y.screen_name)
except tweepy.error.TweepError:
	print(sys.argv[1] + " " + config[API].account)
	exit(1)

try:
	ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
	ssl_context.check_hostname = False
	ssl_context.verify_mode = ssl.CERT_NONE
	client = Elasticsearch(config['STREAM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(config['STREAM']['elksguser'], config['STREAM']['elksgpass']))
except:
	sys.exit()

squish2.perflog(client, "squish", "Just testing")

client.indices.create(index='tw' + config['STREAM']['index'], ignore=400)
client.indices.create(index='tu' + config['STREAM']['index'], ignore=400)

class StreamApi(tweepy.StreamListener):
	def on_status(self, status):
		global twbod
		global tubod
		global cnt
		global config
#		print(status)
		status._json.pop('coordinates', None)
		status._json.pop('contributors', None)
		status._json.pop('is_quote_status', None)
		status._json.pop('in_reply_to_status_id', None)
		status._json.pop('favorite_count', None)
		status._json.pop('in_reply_to_screen_name', None)
		status._json.pop('in_reply_to_user_id', None)
		status._json.pop('retweet_count', None)
		status._json.pop('favorite', None)
		status._json.pop('favorited', None)
		status._json.pop('favorite_count', None)
		status._json.pop('in_reply_to_user_id_str', None)
		status._json.pop('possibly_sensitive', None)
		status._json.pop('in_reply_to_status_id_str', None)
		status._json.pop('quoted_status', None)
		status._json.pop('quoted_status_id', None)
		status._json.pop('quoted_status_id_str', None)
		status._json.pop('retweeted', None)
		#status._json.pop('retweeted_status', None)
		status._json.pop('retweets', None)
		status._json.pop('retweet', None)
		status._json.pop('user.profile_background_color', None)
		status._json.pop('user.profile_background_image_url', None)
		status._json.pop('user.profile_background_image_url_https', None)
		status._json.pop('user.profile_background_tile', None)
		status._json.pop('user.profile_banner_url', None)
		status._json.pop('user.profile_image_url', None)
		status._json.pop('user.profile_image_url_https', None)
		status._json.pop('user.profile_link_color', None)
		status._json.pop('user.profile_location', None)
		status._json.pop('user.profile_sidebar_border_color', None)
		status._json.pop('user.profile_sidebar_fill_color', None)
		status._json.pop('user.profile_text_color', None)
		status._json.pop('user.profile_use_background_image', None)
		status._json['source'] = re.sub("<.*?>", "",status._json['source'])
		status._json['source'] = re.sub("\"", "",status._json['source'])

		twbod = twbod + "{ \"index\" : { \"_index\" : \"tw" + config['STREAM']['index'] + "\", \"_type\" : \"tweets\", \"_id\" : \"" + status.id_str + "\"} }\n"
		twbod = twbod + json.dumps(status._json) + "\n"
		#print(status.user.screen_name + " " + str(status.created_at))
# end twbod type tweets
		aneo = neom.match("user", screen_name=status.user.screen_name).first()
		if(not aneo):
			#how often do we refresh attributes?
			aneo = Node("user",screen_name=status.user.screen_name,id_str=status.user.id_str)
			aneo['created_at'] = re.sub(" ", "T",str(status.user.created_at))
			aneo['followers_count'] = status.user.followers_count
			aneo['friends_count'] = status.user.friends_count
			aneo['listed_count'] = status.user.listed_count
			aneo['statuses_count'] = status.user.statuses_count
		tsource = neom.match("source", source=status.source).first()
		if(not tsource):
			tsource = Node("source",source=status.source)
			tsource[config['STREAM']['index']] = 1
		neog.create(Relationship(aneo, "USES", tsource))

		if(len(status._json['entities']['user_mentions']) > 0):
			for derp in status._json['entities']['user_mentions']:
				bneo = neom.match("user", screen_name=derp['screen_name']).first()
				if(not bneo):
					bneo = Node("user",screen_name=derp['screen_name'],id_str=derp['id_str'])

				aneo[config['STREAM']['index']] = 1
				bneo[config['STREAM']['index']] = 1
				neog.create(Relationship(aneo, "MENTIONS", bneo, created_at=re.sub(" ", "T",str(status.created_at))))
				cnt = cnt + 1
		if(len(status._json['entities']['urls']) > 0):
			if not (re.search("twitter.com",status._json['entities']['urls'][0]['expanded_url'])):			
				print(status._json['entities']['urls'][0]['expanded_url'])
				aurl = Node("url",expurl=status._json['entities']['urls'][0]['expanded_url'],status=status.id_str)
				aurl[config['STREAM']['index']] = 1
				neog.create(Relationship(aneo, "TWEETS", aurl, created_at=re.sub(" ", "T",str(status.created_at))))
# end tmbod type mention
		tubod = tubod + "{ \"index\" : { \"_index\" : \"tu" + config['STREAM']['index'] + "\", \"_type\" : \"twid\", \"_id\" : \"" + status.user.id_str + "\" }\n"
		smuser = squish2.squishuser(status.user)
		tubod = tubod + json.dumps(smuser._json) + "\n"
		cnt = cnt + 1
# end tubod type twid
		try:
			status.retweeted_status
		except:
			cnt = cnt
		else:
			rtuser = squish2.squishuser(status.retweeted_status.user)
			tubod = tubod + "{ \"index\" : { \"_index\" : \"tu" + config['STREAM']['index'] + "\", \"_type\" : \"twid\", \"_id\" : \"" + status.retweeted_status.user.id_str + "\" }\n"
			tubod = tubod + json.dumps(rtuser._json) + "\n"
			cnt = cnt + 1

			bneo = neom.match("user", screen_name=status.retweeted_status.user.screen_name).first()
			if(not bneo):
				bneo = Node("user",screen_name=status.retweeted_status.user.screen_name,id_str=status.retweeted_status.user.id_str)
			bneo[config['STREAM']['index']] = 1
			neog.create(Relationship(aneo, "RTS", bneo, created_at=re.sub(" ", "T",str(status.created_at))))
			cnt = cnt + 1
# end trbod type retweet
			if(cnt > max):
				client.bulk(index="tw" + config['STREAM']['index'],doc_type="tweets",body=twbod)
				client.bulk(index="tu" + config['STREAM']['index'],doc_type="twid",body=tubod)
				print(str(len(twbod)) + " " + str(len(tubod)))
				twbod = ""
				tubod = ""
				cnt = 0


def on_error(self, status):
	if status == 420:
		sys.stderr.write('Enhance Your Calm; The App Is Being Rate Limited For Making Too Many Requests')
		return True
	else:
		sys.stderr.write('Error {}n'.format(status))
		return True

	
streamer = tweepy.Stream(auth=auth, listener=StreamApi(), timeout=30)

tfile = open(sys.argv[1], 'r')
terms = []
text = False
# one letter anywhere indicates text filter stream
# otherwise all numeric is userids
for thing in tfile:
	if(re.search("[a-zA-Z]",thing)):
		text = True	
	terms.append(thing.rstrip())

while True:
	twbod = ""
	tubod = ""
	cnt = 0
	try:
		if(text):
			streamer.filter(None, terms)
		else:
			streamer.filter(follow=terms)
	except (ProtocolError, AttributeError):
#	except tweepy.error.TweepError:
		print("whoops")
#		sys.exit()
