#!/usr/bin/python
import csv, json, os, random, re, sys, time
import urllib2, redis, tweepy
import psutil, getpass, setproctitle
import logging, logging.handlers
from simpleconfigparser import simpleconfigparser
from bs4 import BeautifulSoup
from time import gmtime, strftime
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search

def load_lists():
	y = api.verify_credentials()
	name = y.screen_name

	lists = api.lists_all(name)
	for list in lists:
		# check re for ^trm
		if re.match("trm-", list.slug):
			for member in tweepy.Cursor(api.list_members,name,list.slug).items():
				try:
					# see if its in cache
					y = red.get(member.screen_name)
					if not y:
						z = api.get_user(member.screen_name)
						if z:
							#print(z.screen_name + " " + z.id_str)
							red.set(z.screen_name,z.id_str)
							#print(z.id_str + " " + json.dumps(z._json))
							red.set(z.id_str,json.dumps(z._json))
				except (RuntimeError, TypeError, NameError):
					pass
# load_lists

def get_all_tweets(screen_name):
	new_tweets = api.user_timeline(screen_name = screen_name,count=200)

	for tweet in new_tweets:
		bod = "{ \"index\" : { \"_index\" : \"test\", \"_type\" : \"tweets\" }\n"
		bod = bod + json.dumps(tweet._json) + "}\n"
		try:
			client.bulk(index="test",doc_type="tweets",body=bod)
		except (RuntimeError, TypeError, NameError):
			pass

# get_all_tweets
	

def twalive(acctname):
	#Account does not exist, or account has self-suspended, no way to tell w/o
	#trying to rename another account into the name in question
	try:
		urllib2.urlopen("http://twitter.com/" + acctname)
	except urllib2.URLError:
		return("renamed")

	#Account has been suspended by Twitter - this misses some jihadi accounts maybe UTF-8 again?
	soup = BeautifulSoup(urllib2.urlopen("http://twitter.com/" + acctname), "html5lib")
	for thing in soup("title"):
		if(thing.text == "Twitter / Account Suspended"):
			return("suspended")
	
	#This is the account lookup that gets overloaded, leading to spurious idling
	lookups = api.rate_limit_status()[u'resources'][u'users'][u'/users/show/:id'][u'remaining']
	if (lookups < 10):
		return("API exhausted")
	
	#Account is protected, friendship checks in tweepy just don't work
	#so try to get one tweet to see if we are following the target
	y = api.get_user(acctname)
	if y.protected:
		try:
			cnt = len(api.user_timeline(screen_name = acctname,count=1))
		except tweepy.TweepError:
			return("protected")
	cnt = len(api.user_timeline(screen_name = acctname,count=1))
	if(cnt == 0):
		return("empty")

	return("accessible")
# twalive

def check_resources():
	# make sure prior instance has exited
	for p in psutil.process_iter(attrs=['name', 'username']):
        	if (p.info['username'] == getpass.getuser()) and (p.info['name'] == "trmqueue"):
                	ml.info("already running")
			sys.exit()

	setproctitle.setproctitle("trmqueue")
	#time.sleep(random.random() * 20)

	i = 0
	while (i < 30):
		zcpu = psutil.cpu_percent(interval=None, percpu=False)
		zmem = psutil.virtual_memory()[2]
		if (zcpu < 75) and (zmem < 75):
			i = 60
		i = i + 2
		time.sleep(2)

	#i < 60, don't have resources
	if (i  < 60):
		ml.info("zcpu " + str(zcpu) + " zmem " + str(zmem))
		ml.info("not running due to resource limits")
		sys.exit()

# check_resources
# main begin

# load config
config = simpleconfigparser()
config.read(os.environ['HOME'] +'/.twitter')

# logging will always be used
ml = logging.getLogger('MyLogger')
ml.setLevel(logging.DEBUG)
handler = logging.handlers.SysLogHandler(address=('127.0.0.1', 555), facility=logging.handlers.SysLogHandler.LOG_DAEMON)
ml.addHandler(handler)
ml.info("logging started")

#ensure prior instance has finished, and CPU/MEM usage < 75%
check_resources()
ml.info("resources good")

auth = tweepy.OAuthHandler(config.API.consumer_key, config.API.consumer_secret)
auth.set_access_token(config.API.access_token_key, config.API.access_token_secret)
api = tweepy.API(auth)
ml.info("API auth")

red = redis.StrictRedis(host='localhost', port=6379, db=0)
ml.info("redis connected")

load_lists()
ml.info("lists loaded")

# check twitter API
listlim = api.rate_limit_status()[u'resources'][u'lists'][u'/lists/members'][u'remaining']
tweetlim = api.rate_limit_status()[u'resources'][u'statuses'][u'/statuses/user_timeline'][u'remaining']

ml.info("listlim " + str(listlim) + " tweetlim " + str(tweetlim))

# list semantics go here

if (twalive(sys.argv[1]) == "accessible"):
	# don't bug Elastic till we're sure we've got data to load
	client = Elasticsearch()
	get_all_tweets(sys.argv[1])
