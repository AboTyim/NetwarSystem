#!/usr/bin/python
import csv, json, os, random, re, sys, time, redis, tweepy, getpass, re, math
import configparser
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
import ssl, requests
from elasticsearch.connection import create_ssl_context
import networkx as nx
from scipy.stats.mstats import gmean

#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()


config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')

if(config['STREAM']['elksg'][:5] == "https"):
	try:
		ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		client = Elasticsearch(config['STREAM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(config['STREAM']['elksguser'], config['STREAM']['elksgpass']))
	except:
		sys.exit()
else:
	client = Elasticsearch(config['STREAM']['elksg'])

names = open(sys.argv[1],'r')
DG = nx.DiGraph()

for file in names:
	fname = re.sub(".txt", "",file.rstrip())
	s = Search(using=client, index="usertest").query("match",screen_name=fname)
	response = s.execute()
	if(response):
		for resp in response:
				DG.add_node(fname, faves = resp['favourites_count'], 
							followers = resp['followers_count'],
							friends = resp['friends_count'], 
							listed = resp['listed_count'], 
							statuses = resp['statuses_count'], 
							gmean4=int(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['statuses_count']])),
							gmean5=int(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['listed_count'], resp['statuses_count']])),
							ln1p4=math.log1p(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['statuses_count']])),
							ln1p5=math.log1p(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['listed_count'], resp['statuses_count']])))
	accts = open(fname + ".txt", 'r')
	for line in accts:
		s = Search(using=client, index="usertest").query("match",id_str=line)
		response = s.execute()
		if(response):
			for resp in response:
				print(fname + "," + resp['screen_name'])
				sn = resp['screen_name']
				DG.add_node(sn, faves = resp['favourites_count'], 
					followers = resp['followers_count'],
					friends = resp['friends_count'], 
					listed = resp['listed_count'], 
					statuses = resp['statuses_count'],
					gmean4=int(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['statuses_count']])),
					gmean5=int(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['listed_count'], resp['statuses_count']])),
					ln1p4=math.log1p(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['statuses_count']])),
					ln1p5=math.log1p(gmean([resp['favourites_count'],resp['followers_count'],resp['friends_count'], resp['listed_count'], resp['statuses_count']])))
				DG.add_edge(fname,sn, weight=1)

nx.write_gml(DG,sys.argv[1] + ".gml")
