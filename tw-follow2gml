#!/usr/bin/python
import csv, json, os, random, re, sys, time, redis, tweepy, getpass, re
import configparser
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
import ssl, requests
from elasticsearch.connection import create_ssl_context
import networkx as nx
#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()


config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')

if(config['STREAM']['elksg'][:5] == "https"):
	try:
		ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		client = Elasticsearch(config['STREAM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(config['STREAM']['elksguser'], config['STREAM']['elksgpass']))
	except:
		sys.exit()
else:
	client = Elasticsearch(config['STREAM']['elksg'])

names = open(sys.argv[1],'r')
DG = nx.DiGraph()

for file in names:
	fname = re.sub(".txt", "",file.rstrip())
	accts = open(fname + ".txt", 'r')
	for line in accts:
		s = Search(using=client, index="usertest").query("match",id_str=line)
		response = s.execute()
		if(response):
			for resp in response:
				print(fname + "," + resp['screen_name'])
				sn = resp['screen_name']
				DG.add_node(sn, faves = resp['favourites_count'], followers = resp['followers_count'],friends = resp['friends_count'], listed = resp['listed_count'], statuses = resp['statuses_count'])
				DG.add_edge(fname,sn, weight=1)

nx.write_gml(DG,fname + ".gml")
