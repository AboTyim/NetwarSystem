#!/usr/bin/python
import csv, json, os, random, re, sys, time, redis, tweepy, getpass, datetime
import configparser
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Search
import ssl
from elasticsearch.connection import create_ssl_context
from textblob import TextBlob
import squish2, requests

#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()
sysconf = configparser.ConfigParser()
sysconf.read('/etc/netwar/netwar.conf')

config = configparser.ConfigParser()
config.read(os.environ['HOME'] +'/.twitter')

if(sysconf['SYSTEM']['elksg'][:5] == "https"):
	try:
		ssl_context = create_ssl_context(cafile='/home/root-ca.pem')
		ssl_context.check_hostname = False
		ssl_context.verify_mode = ssl.CERT_NONE
		client = Elasticsearch(sysconf['SYSTEM']['elksg'], ssl_context=ssl_context, timeout=60, http_auth=(sysconf['SYSTEM']['elksguser'], sysconf['SYSTEM']['elksgpass']))
	except:
		sys.exit()
else:
	client = Elasticsearch(sysconf['SYSTEM']['elksg'])

s = Search(using=client, index="usertest").filter('range', status_at={"gte": "now-20y", "lt": "now-19y"})

for response in s.scan():
	print(dir(response))
#	if(not response['protected']):
#		print(response['id_str'] + " " + response['screen_name'] + " " + str(response['statuses_count']) + " " + response['created_at'])



